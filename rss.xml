<?xml version="1.0" encoding="UTF-8"?><rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0"><channel><title><![CDATA[andreveiga.dev blog posts]]></title><description><![CDATA[André Veiga's personal dev-related blog]]></description><link>https://www.andreveiga.dev</link><generator>GatsbyJS</generator><lastBuildDate>Tue, 17 May 2022 22:54:11 GMT</lastBuildDate><item><title><![CDATA[Setting up a Kubernetes cluster using Raspberry Pi Zero 2 W's]]></title><description><![CDATA[Introduction This week I wanted to challenge myself and try to create a Kubernetes cluster on 3 of my Raspberry Pi Zero 2 W’s. These Pi’s…]]></description><link>https://www.andreveiga.dev/rpizero-k3s-cluster/</link><guid isPermaLink="false">https://www.andreveiga.dev/rpizero-k3s-cluster/</guid><pubDate>Tue, 17 May 2022 19:00:00 GMT</pubDate><content:encoded>&lt;h1&gt;Introduction&lt;/h1&gt;
&lt;p&gt;This week I wanted to challenge myself and try to create a Kubernetes cluster on 3 of my Raspberry Pi Zero 2 W’s. These Pi’s are somewhat underpowered for the task, especially in regards to their RAM, and I hoped to learn a trick or two on setting up High Availability on such a constrained environment.&lt;/p&gt;
&lt;p&gt;If you’ve read my previous posts, you’ll know that I’m using &lt;a href=&quot;https://k3s.io&quot;&gt;k3s&lt;/a&gt;, from Rancher Labs. It’s light-weight, full-featured, and highly configurable. The perfect fit for this use case.&lt;/p&gt;
&lt;h1&gt;Solution&lt;/h1&gt;
&lt;p&gt;Highly available cluster will always need 3 Kubernetes nodes, at the very least, as per the &lt;a href=&quot;https://raft.github.io&quot;&gt;Raft Algorithm&lt;/a&gt; used by etcd, the Kubernetes Control Plane database. This is, of course, assuming that application workloads are schedulable to the master nodes. If that’s not the case, as best practices dictate, then you need an Highly Available Control Plane (3 or more nodes) plus a number of worker nodes, depending on your own workload.&lt;/p&gt;
&lt;p&gt;In this exercise, for simplicity purposes, I’m using three Raspberry Pi Zero W’s that will run both the Control Plane as well as the application workloads. At least that was the plan…&lt;/p&gt;
&lt;h2&gt;Attempt #1: Running the standard k3s installation - Failed&lt;/h2&gt;
&lt;p&gt;My first approach was to ignore k3s’ minimum hardware requirements and simply run the installer with no further deployment customizations. This proved to be impossible, as the k3s daemon didn’t even start due to insufficient memory on the Raspberry Pi. Nonetheless, this is how I went about it:&lt;/p&gt;
&lt;p&gt;The first node is pretty simple, just run the regular k3s install script:&lt;/p&gt;
&lt;div class=&quot;gatsby-highlight&quot; data-language=&quot;bash&quot;&gt;&lt;pre class=&quot;language-bash&quot;&gt;&lt;code class=&quot;language-bash&quot;&gt;&lt;span class=&quot;token function&quot;&gt;curl&lt;/span&gt; -sfL https://get.k3s.io &lt;span class=&quot;token operator&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;token function&quot;&gt;sh&lt;/span&gt; -s - server --cluster-init&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;The next two Kubernetes nodes are setup by running:&lt;/p&gt;
&lt;div class=&quot;gatsby-highlight&quot; data-language=&quot;bash&quot;&gt;&lt;pre class=&quot;language-bash&quot;&gt;&lt;code class=&quot;language-bash&quot;&gt;&lt;span class=&quot;token function&quot;&gt;curl&lt;/span&gt; -sfL https://get.k3s.io &lt;span class=&quot;token operator&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;token function&quot;&gt;sh&lt;/span&gt; -s - server --server https://&lt;span class=&quot;token operator&quot;&gt;&amp;lt;&lt;/span&gt;ip or &lt;span class=&quot;token function&quot;&gt;hostname&lt;/span&gt; of server&lt;span class=&quot;token operator&quot;&gt;&lt;span class=&quot;token file-descriptor important&quot;&gt;1&lt;/span&gt;&gt;&lt;/span&gt;:6443&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;This should give you an HA cluster where the master nodes are schedulable. Not possible with Pi Zero 2’s, apparently, but more than possible with Pi 4’s (or even Pi 3’s).&lt;/p&gt;
&lt;h2&gt;Attempt #2: Externalizing the Control Plane DB&lt;/h2&gt;
&lt;p&gt;By default, k3s will run an embedded etcd as the Control Plane DB. It’s well documented that this solution may have &lt;a href=&quot;https://rancher.com/docs/k3s/latest/en/installation/ha-embedded/&quot;&gt;“performance issues on slower disks such as Raspberry Pis running with SD cards”&lt;/a&gt;, so I though running an external DB to act as the Kubernetes Control Plane would maybe easy the load on the Pi Zero’s… Luckily, this is supported out-of-the-box by k3s.&lt;/p&gt;
&lt;p&gt;First of all, you have to choose between using PostgreSQL, MySQL, MariaDB and (external) etcd. I went with PostgreSQL as I’m more familiar with it.&lt;/p&gt;
&lt;p&gt;Since this needs to run externally (and the point is to remove the extra load from the Pi’s), I’m running PostreSQL in Docker in my own Mac. This is the docker-compose file I’ve used:&lt;/p&gt;
&lt;div class=&quot;gatsby-highlight&quot; data-language=&quot;yaml&quot;&gt;&lt;pre class=&quot;language-yaml&quot;&gt;&lt;code class=&quot;language-yaml&quot;&gt;&lt;span class=&quot;token key atrule&quot;&gt;version&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;token string&quot;&gt;&quot;3.0&quot;&lt;/span&gt;
&lt;span class=&quot;token key atrule&quot;&gt;services&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;token key atrule&quot;&gt;postgres&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;token key atrule&quot;&gt;image&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;:&lt;/span&gt; postgres
    &lt;span class=&quot;token key atrule&quot;&gt;restart&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;:&lt;/span&gt; always
    &lt;span class=&quot;token key atrule&quot;&gt;volumes&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;:&lt;/span&gt;
      &lt;span class=&quot;token punctuation&quot;&gt;-&lt;/span&gt; pg&lt;span class=&quot;token punctuation&quot;&gt;:&lt;/span&gt;/var/lib/postgresql/data/pgdata
    &lt;span class=&quot;token key atrule&quot;&gt;ports&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;:&lt;/span&gt;
      &lt;span class=&quot;token punctuation&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;token string&quot;&gt;&quot;5450:5432&quot;&lt;/span&gt;
    &lt;span class=&quot;token key atrule&quot;&gt;environment&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;:&lt;/span&gt;
      &lt;span class=&quot;token key atrule&quot;&gt;POSTGRES_PASSWORD&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;:&lt;/span&gt; postgres
      &lt;span class=&quot;token key atrule&quot;&gt;PGDATA&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;:&lt;/span&gt; /var/lib/postgresql/data/pgdata

&lt;span class=&quot;token key atrule&quot;&gt;volumes&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;:&lt;/span&gt;
  pg&lt;span class=&quot;token punctuation&quot;&gt;:&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;After spinning up the PostgreSQL container, you’ll need to create a DB called &lt;code class=&quot;language-text&quot;&gt;kubernetes&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;We now need to pass the DB connection string to the k3s server setup commands.&lt;/p&gt;
&lt;p&gt;In this setup, since etcd isn’t really running in the Kubernetes cluster, we only really need two nodes to achieve High Availability (even though we’d have to deal with PostgreSQL high availability as well… but that’s a different topic).&lt;/p&gt;
&lt;p&gt;The following command can be run in all nodes to create a cluster:&lt;/p&gt;
&lt;div class=&quot;gatsby-highlight&quot; data-language=&quot;bash&quot;&gt;&lt;pre class=&quot;language-bash&quot;&gt;&lt;code class=&quot;language-bash&quot;&gt;&lt;span class=&quot;token function&quot;&gt;curl&lt;/span&gt; -sfL https://get.k3s.io &lt;span class=&quot;token operator&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;token function&quot;&gt;sh&lt;/span&gt; -s - server --token&lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;token operator&quot;&gt;&amp;lt;&lt;/span&gt;SECRET&lt;span class=&quot;token operator&quot;&gt;&gt;&lt;/span&gt; --datastore-endpoint&lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;token string&quot;&gt;&quot;postgres://postgres:postgres@&amp;lt;PostgreSQL Server IP Address&gt;:5450/kubernetes?sslmode=disable&quot;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;In the end, this proved not to be enough. The rest of the Control Plane components are still too heavy for the Pi Zero’s…&lt;/p&gt;
&lt;h2&gt;Attempt #3: Splitting the control plane components over the different Pi’s - Also failed&lt;/h2&gt;
&lt;p&gt;k3s provides a few useful flags to disable the Kubernetes Control Plane components. Plus, remember when I mentioned that k3s is a full-featured Kubernetes distro? What that means is that k3s comes bundled with a number of useful components that are commonly needed to run a production cluster: Load Balancer, Ingress Controller, Local Storage Provider and a Metrics Server.&lt;/p&gt;
&lt;p&gt;While these are indeed needed in most situations where k3s is meant to be run, that’s not really the case for my exercise where I’m learning about k3s sizing and cluster stability. Thus, my next though was to:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Disable all unnecessary components&lt;/li&gt;
&lt;li&gt;Run the different Control Plane components on different Pi’s&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;This has a number of disadvantages, namely the complete lack of High Availability with just 3 servers (what if the Pi running etcd goes down? Or the Pi running the API Server?). This is how you can run k3s, disabling, for example, the Scheduler and Traefik (the Ingress Controller):&lt;/p&gt;
&lt;div class=&quot;gatsby-highlight&quot; data-language=&quot;bash&quot;&gt;&lt;pre class=&quot;language-bash&quot;&gt;&lt;code class=&quot;language-bash&quot;&gt;&lt;span class=&quot;token function&quot;&gt;curl&lt;/span&gt; -sfL https://get.k3s.io &lt;span class=&quot;token operator&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;token function&quot;&gt;sh&lt;/span&gt; -s - server --cluster-init --disable-scheduler --disable traefik&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Even in this scenario it was still too much for the poor Pi Zero’s. You can learn more about k3s feature flags &lt;a href=&quot;https://rancher.com/docs/k3s/latest/en/installation/install-options/server-config/&quot;&gt;here&lt;/a&gt; and about etcd only nodes &lt;a href=&quot;https://rancher.com/docs/k3s/latest/en/installation/disable-flags/&quot;&gt;here&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;Attempt #4: Running the control plane on an external VM - Great Success 🚀&lt;/h2&gt;
&lt;p&gt;So… that was it. I had to accept that running the Control Plane on the Pi Zero’s was a bit too much, for now… Which shouldn’t be a surprise, given &lt;a href=&quot;https://rancher.com/docs/k3s/latest/en/installation/installation-requirements/resource-profiling/&quot;&gt;k3s’ minimum hardware requirements&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Nonetheless, I wanted to follow thorough with this. A highly available app deployment will still be running even if the Control Plane goes down! This means that we can run an entire master node externally and use the Pi’s as worker nodes, to deploy highly available app workloads.&lt;/p&gt;
&lt;p&gt;I’ve then created a VM on my Mac where I’ve installed a k3s master node:&lt;/p&gt;
&lt;div class=&quot;gatsby-highlight&quot; data-language=&quot;bash&quot;&gt;&lt;pre class=&quot;language-bash&quot;&gt;&lt;code class=&quot;language-bash&quot;&gt;&lt;span class=&quot;token function&quot;&gt;curl&lt;/span&gt; -fL https://get.k3s.io &lt;span class=&quot;token operator&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;token function&quot;&gt;sh&lt;/span&gt; -s - server&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;And run the agent node installation on the Raspberry Pi’s as follows:&lt;/p&gt;
&lt;div class=&quot;gatsby-highlight&quot; data-language=&quot;bash&quot;&gt;&lt;pre class=&quot;language-bash&quot;&gt;&lt;code class=&quot;language-bash&quot;&gt;&lt;span class=&quot;token function&quot;&gt;curl&lt;/span&gt; -fL https://get.k3s.io &lt;span class=&quot;token operator&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;token function&quot;&gt;sh&lt;/span&gt; -s - agent&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;There is, of course, a bit more to this. k3s can consume installation configuration from a &lt;code class=&quot;language-text&quot;&gt;config.yaml&lt;/code&gt; file which is preemptively placed at &lt;code class=&quot;language-text&quot;&gt;/etc/rancher/k3s/&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;The master node config file looks like this:&lt;/p&gt;
&lt;div class=&quot;gatsby-highlight&quot; data-language=&quot;bash&quot;&gt;&lt;pre class=&quot;language-bash&quot;&gt;&lt;code class=&quot;language-bash&quot;&gt;node-name: &lt;span class=&quot;token punctuation&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;{&lt;/span&gt; inventory_hostname &lt;span class=&quot;token punctuation&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;}&lt;/span&gt;
cluster-init: &lt;span class=&quot;token boolean&quot;&gt;true&lt;/span&gt;
node-taint: &lt;span class=&quot;token string&quot;&gt;&quot;CriticalAddonsOnly=true:NoExecute&quot;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;and the agent node config file looks like this:&lt;/p&gt;
&lt;div class=&quot;gatsby-highlight&quot; data-language=&quot;bash&quot;&gt;&lt;pre class=&quot;language-bash&quot;&gt;&lt;code class=&quot;language-bash&quot;&gt;node-name: &lt;span class=&quot;token punctuation&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;{&lt;/span&gt; inventory_hostname &lt;span class=&quot;token punctuation&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;}&lt;/span&gt;
token: &lt;span class=&quot;token string&quot;&gt;&quot;{{ hostvars[&apos;vm&apos;][&apos;token&apos;].stdout }}&quot;&lt;/span&gt;
server: &lt;span class=&quot;token string&quot;&gt;&quot;https://{{ hostvars[&apos;vm&apos;][&apos;ansible_host&apos;] }}:6443&quot;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Also, a few boot command line options need to be set on all Raspberry Pi’s. The &lt;code class=&quot;language-text&quot;&gt;/boot/cmdline.txt&lt;/code&gt; should look like this (notice the &lt;code class=&quot;language-text&quot;&gt;cgroup_memory=1 cgroup_enable=memory&lt;/code&gt; options at the end of the line):&lt;/p&gt;
&lt;div class=&quot;gatsby-highlight&quot; data-language=&quot;text&quot;&gt;&lt;pre class=&quot;language-text&quot;&gt;&lt;code class=&quot;language-text&quot;&gt;console=serial-1,115200 console=tty1 root=PARTUUID=01decd83-02 rootfstype=ext4 fsck.repair=yes rootwait cgroup_memory=1 cgroup_enable=memory&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;By the way, did you notice the strange &lt;code class=&quot;language-text&quot;&gt;{{ ... }}&lt;/code&gt; syntax in some of the code sample above? This leads me to the next section…&lt;/p&gt;
&lt;h1&gt;Automation&lt;/h1&gt;
&lt;p&gt;As always, my true documentation is on GitHub, delivery as a set of Ansible Playbooks. You can &lt;a href=&quot;https://github.com/aveiga/rpizero-k3s-cluster&quot;&gt;take a look at it, clone it and/or fork it here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;This has been thoroughly tested running the Playbooks from my M1 Macbook Air, and will result on a VM running the Kubernetes cluster master node (unschedulable for app workloads) and the three Raspberry Pi’s running the cluster’s worker nodes.&lt;/p&gt;
&lt;p&gt;Don’t forget to adapt the &lt;a href=&quot;https://github.com/aveiga/rpizero-k3s-cluster/blob/main/hosts.yaml&quot;&gt;hosts.yaml&lt;/a&gt; file to your own environment, as well as recreating the Ansible &lt;a href=&quot;https://github.com/aveiga/rpizero-k3s-cluster/blob/main/group_vars/all/vault&quot;&gt;Vault&lt;/a&gt; defining your own variables:&lt;/p&gt;
&lt;div class=&quot;gatsby-highlight&quot; data-language=&quot;yaml&quot;&gt;&lt;pre class=&quot;language-yaml&quot;&gt;&lt;code class=&quot;language-yaml&quot;&gt;&lt;span class=&quot;token key atrule&quot;&gt;vaulted_become_password&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;:&lt;/span&gt; TBD &lt;span class=&quot;token comment&quot;&gt;# The password used to run commands with elevated privileges&lt;/span&gt;
&lt;span class=&quot;token key atrule&quot;&gt;vaulted_ssh_user&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;:&lt;/span&gt; TBD &lt;span class=&quot;token comment&quot;&gt;# The user used to SSH into the Pi&apos;s&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;</content:encoded></item><item><title><![CDATA[Installing K3s and Knative on ARM]]></title><description><![CDATA[Installation This past week I wanted to try out Knative, a “Kubernetes-based platform to deploy and manage modern serverless workloads”. In…]]></description><link>https://www.andreveiga.dev/k3s-knative-arm/</link><guid isPermaLink="false">https://www.andreveiga.dev/k3s-knative-arm/</guid><pubDate>Sun, 16 Jan 2022 19:00:00 GMT</pubDate><content:encoded>&lt;h2&gt;Installation&lt;/h2&gt;
&lt;p&gt;This past week I wanted to try out &lt;a href=&quot;https://knative.dev/docs/&quot;&gt;Knative&lt;/a&gt;, a “Kubernetes-based platform to deploy and manage modern serverless workloads”. In essence, what I’m looking forward is a higher level abstration for running applications/microservices without worrying with Kubernetes inherent complexities.&lt;/p&gt;
&lt;p&gt;I’ve been using &lt;a href=&quot;https://k3s.io&quot;&gt;K3s&lt;/a&gt;, a light-weight Kubernetes distribution built by the team behind &lt;a href=&quot;https://rancher.com&quot;&gt;Rancher&lt;/a&gt; for all of my deployments for a while. It’s easy and fast to install, highly scalable and has a minimal footprint, perfect for on-premises and self-managed deployments.&lt;/p&gt;
&lt;p&gt;K3s comes with it’s own network layer, provided by Traefik. However, since Knative needs to takeover the networking layer in order to successfully run applications as Knative Services, Traefik needs to be disabled. It’s possible to install K3s without Traefik by running the following command:&lt;/p&gt;
&lt;div class=&quot;gatsby-highlight&quot; data-language=&quot;bash&quot;&gt;&lt;pre class=&quot;language-bash&quot;&gt;&lt;code class=&quot;language-bash&quot;&gt;&lt;span class=&quot;token function&quot;&gt;curl&lt;/span&gt; -sfL https://get.k3s.io &lt;span class=&quot;token operator&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;token function&quot;&gt;sh&lt;/span&gt; -s - --disable traefik&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;After this, to install Knative, just follow the &lt;a href=&quot;https://knative.dev/docs/install/serving/install-serving-with-yaml/&quot;&gt;Knative installation guide&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Finally, to try out and “smoke test” the installation, I’ve created the following Knative Service definition (which deploys Nginx as a Knative Service)…&lt;/p&gt;
&lt;div class=&quot;gatsby-highlight&quot; data-language=&quot;yaml&quot;&gt;&lt;pre class=&quot;language-yaml&quot;&gt;&lt;code class=&quot;language-yaml&quot;&gt;&lt;span class=&quot;token comment&quot;&gt;# hello.yaml&lt;/span&gt;
&lt;span class=&quot;token punctuation&quot;&gt;---&lt;/span&gt;
&lt;span class=&quot;token key atrule&quot;&gt;apiVersion&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;:&lt;/span&gt; serving.knative.dev/v1
&lt;span class=&quot;token key atrule&quot;&gt;kind&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;:&lt;/span&gt; Service
&lt;span class=&quot;token key atrule&quot;&gt;metadata&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;token key atrule&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;:&lt;/span&gt; hello
&lt;span class=&quot;token key atrule&quot;&gt;spec&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;token key atrule&quot;&gt;template&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;token key atrule&quot;&gt;metadata&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;:&lt;/span&gt;
      &lt;span class=&quot;token comment&quot;&gt;# This is the name of our new &quot;Revision,&quot; it must follow the convention {service-name}-{revision-name}&lt;/span&gt;
      &lt;span class=&quot;token key atrule&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;:&lt;/span&gt; hello&lt;span class=&quot;token punctuation&quot;&gt;-&lt;/span&gt;nginx
    &lt;span class=&quot;token key atrule&quot;&gt;spec&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;:&lt;/span&gt;
      &lt;span class=&quot;token key atrule&quot;&gt;containers&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;token punctuation&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;token key atrule&quot;&gt;image&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;:&lt;/span&gt; nginx
          &lt;span class=&quot;token key atrule&quot;&gt;ports&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;token punctuation&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;token key atrule&quot;&gt;containerPort&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;token number&quot;&gt;80&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;…and applied it with the the following command:&lt;/p&gt;
&lt;div class=&quot;gatsby-highlight&quot; data-language=&quot;bash&quot;&gt;&lt;pre class=&quot;language-bash&quot;&gt;&lt;code class=&quot;language-bash&quot;&gt;&lt;span class=&quot;token function&quot;&gt;sudo&lt;/span&gt; kubectl apply -f hello.world&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;You can then get the application URL by listing the Knative Services (note that you’ll need the Knative CLI, &lt;code class=&quot;language-text&quot;&gt;kn&lt;/code&gt;, installed):&lt;/p&gt;
&lt;div class=&quot;gatsby-highlight&quot; data-language=&quot;bash&quot;&gt;&lt;pre class=&quot;language-bash&quot;&gt;&lt;code class=&quot;language-bash&quot;&gt;kn &lt;span class=&quot;token function&quot;&gt;service&lt;/span&gt; list&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h2&gt;Automation&lt;/h2&gt;
&lt;p&gt;I’ve created a set of &lt;a href=&quot;https://www.ansible.com&quot;&gt;Ansible&lt;/a&gt; playbooks to deploy K3s, Knative (and a “smoke test” application) on ARM and made them available in &lt;a href=&quot;https://github.com/aveiga/k3s-knative-arm&quot;&gt;this GitHub repo&lt;/a&gt;. Hope it makes your life easier, when testing Knative.&lt;/p&gt;</content:encoded></item><item><title><![CDATA[Documentation, Automation and Ansible]]></title><description><![CDATA[I’ve been religiously documenting every step I do when learning something new for a long time. I tend to forget things easily, especially…]]></description><link>https://www.andreveiga.dev/automation/</link><guid isPermaLink="false">https://www.andreveiga.dev/automation/</guid><pubDate>Sun, 16 Jan 2022 19:00:00 GMT</pubDate><content:encoded>&lt;p&gt;I’ve been religiously documenting every step I do when learning something new for a long time. I tend to forget things easily, especially when not really practicing them every day, so my personal defense has been to write down anything that might help me when coming back to the topic at hand many months (and sometimes years) later. A bit like a &lt;a href=&quot;https://en.wikipedia.org/wiki/Zettelkasten&quot;&gt;Zetellkasten&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Lately, I’ve moved from simply taking notes for myself to actually automating whatever it is I’m working on. I’ve found that it makes me actually dig a bit deeper, remember and learn more effectively and be 100% thorough in my documentation.&lt;/p&gt;
&lt;p&gt;Like many, I’ve started with Bash, since it’s readily available and simple. However, I find that Bash codebases tend to grow out of control quite easily, becoming a mess of tangled, unreadable code. Since some months ago, I’ve started to play around with &lt;a href=&quot;https://www.ansible.com&quot;&gt;Ansible&lt;/a&gt; and have completely fallen in love with it. It’s easy to begin with and grows with you as you need it to, helps keep the automation well structured and, if you follow the &lt;a href=&quot;https://docs.ansible.com/ansible/2.8/user_guide/playbooks_best_practices.html&quot;&gt;best practices&lt;/a&gt;, will make all your automation scripts immutable by default (mandatory shoutout to &lt;a href=&quot;https://www.jeffgeerling.com&quot;&gt;Jeff Geerling&lt;/a&gt; and &lt;a href=&quot;https://www.ansiblefordevops.com&quot;&gt;it’s book&lt;/a&gt; and &lt;a href=&quot;https://youtu.be/goclfp6a2IQ&quot;&gt;YouTube series&lt;/a&gt; on Ansible, from whom I’ve learned most of what I know).&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://github.com/aveiga/k3s-knative-arm&quot;&gt;Here’s an example&lt;/a&gt; of some of my Ansible playbooks, in this case deploying K3s and Knative on ARM.&lt;/p&gt;</content:encoded></item></channel></rss>